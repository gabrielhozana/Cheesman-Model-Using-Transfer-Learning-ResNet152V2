{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Cheesman Model Using Transfer Learning ResNet152V2.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOe4FUb+D04nVoGAaEEjgkq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gabrielhozana/Cheesman-Model-Using-Transfer-Learning-ResNet152V2/blob/main/Cheesman_Model_Using_Transfer_Learning_ResNet152V2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tmPicBd6SDga",
        "outputId": "ac5a6abc-1dea-4ae5-dd09-39413f1b5044"
      },
      "source": [
        "!wget --no-check-certificate \\\n",
        "  https://dicodingacademy.blob.core.windows.net/picodiploma/ml_pengembangan_academy/Chessman-image-dataset.zip \\\n",
        "  -O /tmp/Chessman-image-dataset.zip"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-06-29 01:38:49--  https://dicodingacademy.blob.core.windows.net/picodiploma/ml_pengembangan_academy/Chessman-image-dataset.zip\n",
            "Resolving dicodingacademy.blob.core.windows.net (dicodingacademy.blob.core.windows.net)... 52.239.197.36\n",
            "Connecting to dicodingacademy.blob.core.windows.net (dicodingacademy.blob.core.windows.net)|52.239.197.36|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 60684125 (58M) [application/zip]\n",
            "Saving to: ‘/tmp/Chessman-image-dataset.zip’\n",
            "\n",
            "/tmp/Chessman-image 100%[===================>]  57.87M  5.17MB/s    in 13s     \n",
            "\n",
            "2021-06-29 01:39:03 (4.49 MB/s) - ‘/tmp/Chessman-image-dataset.zip’ saved [60684125/60684125]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oJUd8PSiTGkC"
      },
      "source": [
        "import os\n",
        "import zipfile\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "local_zip = '/tmp/Chessman-image-dataset.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp')\n",
        "zip_ref.close()\n",
        "train_dir = os.path.join('/tmp/Chessman-image-dataset/Chess')\n",
        "#membuat augmentasi \n",
        "train_datagen = ImageDataGenerator(rescale=1./255,\n",
        "                                   rotation_range=20,\n",
        "                                   zoom_range=0.2,\n",
        "                                   shear_range=0.2,\n",
        "                                   fill_mode = 'nearest',\n",
        "                                   validation_split=0.1) # set validation split"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W0yJQgVPT1rI",
        "outputId": "bf978ed5-75db-4852-b487-e771be21b794"
      },
      "source": [
        "#Bagi dataset menjadi data training dan data validasi.\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(150, 150),\n",
        "    batch_size=8,\n",
        "    class_mode='categorical',\n",
        "    subset='training') # set as training data\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "    train_dir, # same directory as training data\n",
        "    target_size=(150, 150),\n",
        "    batch_size=16,\n",
        "    class_mode='categorical',\n",
        "    subset='validation')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 499 images belonging to 6 classes.\n",
            "Found 52 images belonging to 6 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hy8Aq6b5ULn6"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.applications import ResNet152V2\n",
        "model = tf.keras.models.Sequential([\n",
        "                                    #menggunakan model ResNet152V2 untuk transfer learning\n",
        "                                    #weights: kita ingin menggunakan model ResNet152V2 yang telah dilatih pada dataset imagenet.\n",
        "                                    #Include_top: Maksud dari parameter ini apabila kita ingin tetap memakai layer terakhir/layer prediksi dari model resnet. Kita isi false karena kita memakai model resnet untuk memprediksi dataset chessman bukan imagenet.\n",
        "                                    #Input_tensor : sesuai namanya parameter ini menspesifikasikan ukuran dari input.\n",
        "                                    ResNet152V2(weights=\"imagenet\", include_top=False, input_tensor=Input(shape=(150, 150, 3))),\n",
        "                                    # tf.keras.layers.Dropout(0.4),\n",
        "                                    tf.keras.layers.Flatten(),\n",
        "                                    tf.keras.layers.Dense(512, activation='relu'),\n",
        "                                    tf.keras.layers.Dense(256, activation='relu'),\n",
        "                                    tf.keras.layers.Dense(6, activation='softmax')\n",
        "                                    ])\n",
        "model.layers[0].trainable = False"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vwxivqMnV06z"
      },
      "source": [
        "#menentukan optimizer, loss dan metrik\n",
        "model.compile(optimizer=tf.optimizers.Adam(),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics = ['accuracy'])"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_J-nXzIzWAo4",
        "outputId": "595cf921-b02a-4b95-a22c-097db8af69ea"
      },
      "source": [
        "history = model.fit(train_generator,\n",
        "                    validation_data=validation_generator,\n",
        "                    epochs=50,\n",
        "                    verbose=2)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "63/63 - 106s - loss: 8.7658 - accuracy: 0.4208 - val_loss: 3.5285 - val_accuracy: 0.5192\n",
            "Epoch 2/50\n",
            "63/63 - 95s - loss: 1.6916 - accuracy: 0.6593 - val_loss: 0.9051 - val_accuracy: 0.6923\n",
            "Epoch 3/50\n",
            "63/63 - 95s - loss: 0.8626 - accuracy: 0.7876 - val_loss: 1.7091 - val_accuracy: 0.5962\n",
            "Epoch 4/50\n",
            "63/63 - 95s - loss: 0.7003 - accuracy: 0.8016 - val_loss: 2.5608 - val_accuracy: 0.5192\n",
            "Epoch 5/50\n",
            "63/63 - 95s - loss: 0.7423 - accuracy: 0.8176 - val_loss: 1.1268 - val_accuracy: 0.7500\n",
            "Epoch 6/50\n",
            "63/63 - 95s - loss: 0.7494 - accuracy: 0.8036 - val_loss: 0.8826 - val_accuracy: 0.7115\n",
            "Epoch 7/50\n",
            "63/63 - 95s - loss: 0.6293 - accuracy: 0.8417 - val_loss: 1.4840 - val_accuracy: 0.6154\n",
            "Epoch 8/50\n",
            "63/63 - 95s - loss: 0.5264 - accuracy: 0.8457 - val_loss: 0.7512 - val_accuracy: 0.8077\n",
            "Epoch 9/50\n",
            "63/63 - 96s - loss: 0.3564 - accuracy: 0.9038 - val_loss: 1.9136 - val_accuracy: 0.6154\n",
            "Epoch 10/50\n",
            "63/63 - 95s - loss: 0.5038 - accuracy: 0.8758 - val_loss: 0.9579 - val_accuracy: 0.7115\n",
            "Epoch 11/50\n",
            "63/63 - 95s - loss: 0.3806 - accuracy: 0.8998 - val_loss: 0.5509 - val_accuracy: 0.8077\n",
            "Epoch 12/50\n",
            "63/63 - 97s - loss: 0.2728 - accuracy: 0.9379 - val_loss: 1.5818 - val_accuracy: 0.7692\n",
            "Epoch 13/50\n",
            "63/63 - 97s - loss: 0.3373 - accuracy: 0.9038 - val_loss: 0.9565 - val_accuracy: 0.8269\n",
            "Epoch 14/50\n",
            "63/63 - 96s - loss: 0.2023 - accuracy: 0.9319 - val_loss: 0.8618 - val_accuracy: 0.8462\n",
            "Epoch 15/50\n",
            "63/63 - 96s - loss: 0.2990 - accuracy: 0.9218 - val_loss: 1.1086 - val_accuracy: 0.7308\n",
            "Epoch 16/50\n",
            "63/63 - 96s - loss: 0.2332 - accuracy: 0.9479 - val_loss: 1.0113 - val_accuracy: 0.7500\n",
            "Epoch 17/50\n",
            "63/63 - 96s - loss: 0.2851 - accuracy: 0.9339 - val_loss: 1.0147 - val_accuracy: 0.7308\n",
            "Epoch 18/50\n",
            "63/63 - 96s - loss: 0.2468 - accuracy: 0.9379 - val_loss: 1.5276 - val_accuracy: 0.6923\n",
            "Epoch 19/50\n",
            "63/63 - 95s - loss: 0.1892 - accuracy: 0.9379 - val_loss: 0.6689 - val_accuracy: 0.8077\n",
            "Epoch 20/50\n",
            "63/63 - 95s - loss: 0.1551 - accuracy: 0.9499 - val_loss: 1.0162 - val_accuracy: 0.7115\n",
            "Epoch 21/50\n",
            "63/63 - 95s - loss: 0.4435 - accuracy: 0.9078 - val_loss: 0.7480 - val_accuracy: 0.8269\n",
            "Epoch 22/50\n",
            "63/63 - 95s - loss: 0.2883 - accuracy: 0.9259 - val_loss: 0.6731 - val_accuracy: 0.8462\n",
            "Epoch 23/50\n",
            "63/63 - 95s - loss: 0.5938 - accuracy: 0.8978 - val_loss: 1.2674 - val_accuracy: 0.7308\n",
            "Epoch 24/50\n",
            "63/63 - 95s - loss: 0.5091 - accuracy: 0.9158 - val_loss: 1.6789 - val_accuracy: 0.6923\n",
            "Epoch 25/50\n",
            "63/63 - 95s - loss: 0.2758 - accuracy: 0.9279 - val_loss: 1.8304 - val_accuracy: 0.7500\n",
            "Epoch 26/50\n",
            "63/63 - 95s - loss: 0.3546 - accuracy: 0.9238 - val_loss: 1.1092 - val_accuracy: 0.7885\n",
            "Epoch 27/50\n",
            "63/63 - 95s - loss: 0.2025 - accuracy: 0.9519 - val_loss: 1.2384 - val_accuracy: 0.7692\n",
            "Epoch 28/50\n",
            "63/63 - 95s - loss: 0.3221 - accuracy: 0.9259 - val_loss: 1.1736 - val_accuracy: 0.7500\n",
            "Epoch 29/50\n",
            "63/63 - 96s - loss: 0.5411 - accuracy: 0.9238 - val_loss: 1.0226 - val_accuracy: 0.7885\n",
            "Epoch 30/50\n",
            "63/63 - 95s - loss: 0.1532 - accuracy: 0.9659 - val_loss: 0.9754 - val_accuracy: 0.7885\n",
            "Epoch 31/50\n",
            "63/63 - 95s - loss: 0.2075 - accuracy: 0.9539 - val_loss: 2.0216 - val_accuracy: 0.7692\n",
            "Epoch 32/50\n",
            "63/63 - 97s - loss: 0.2092 - accuracy: 0.9499 - val_loss: 1.6349 - val_accuracy: 0.7308\n",
            "Epoch 33/50\n",
            "63/63 - 96s - loss: 0.3224 - accuracy: 0.9259 - val_loss: 1.3552 - val_accuracy: 0.7115\n",
            "Epoch 34/50\n",
            "63/63 - 96s - loss: 0.4610 - accuracy: 0.9279 - val_loss: 0.5379 - val_accuracy: 0.8462\n",
            "Epoch 35/50\n",
            "63/63 - 96s - loss: 0.5839 - accuracy: 0.9198 - val_loss: 0.7358 - val_accuracy: 0.8269\n",
            "Epoch 36/50\n",
            "63/63 - 98s - loss: 0.3795 - accuracy: 0.9279 - val_loss: 0.8618 - val_accuracy: 0.7885\n",
            "Epoch 37/50\n",
            "63/63 - 96s - loss: 0.2433 - accuracy: 0.9579 - val_loss: 1.3544 - val_accuracy: 0.7308\n",
            "Epoch 38/50\n",
            "63/63 - 97s - loss: 0.2074 - accuracy: 0.9519 - val_loss: 0.8434 - val_accuracy: 0.7885\n",
            "Epoch 39/50\n",
            "63/63 - 96s - loss: 0.1944 - accuracy: 0.9539 - val_loss: 0.4543 - val_accuracy: 0.8269\n",
            "Epoch 40/50\n",
            "63/63 - 95s - loss: 0.1907 - accuracy: 0.9619 - val_loss: 1.0140 - val_accuracy: 0.7885\n",
            "Epoch 41/50\n",
            "63/63 - 96s - loss: 0.0542 - accuracy: 0.9820 - val_loss: 0.4940 - val_accuracy: 0.8654\n",
            "Epoch 42/50\n",
            "63/63 - 97s - loss: 0.1200 - accuracy: 0.9719 - val_loss: 1.0864 - val_accuracy: 0.7692\n",
            "Epoch 43/50\n",
            "63/63 - 97s - loss: 0.0296 - accuracy: 0.9940 - val_loss: 0.7565 - val_accuracy: 0.8462\n",
            "Epoch 44/50\n",
            "63/63 - 96s - loss: 0.0751 - accuracy: 0.9880 - val_loss: 0.8375 - val_accuracy: 0.8462\n",
            "Epoch 45/50\n",
            "63/63 - 96s - loss: 0.1019 - accuracy: 0.9760 - val_loss: 0.6926 - val_accuracy: 0.8077\n",
            "Epoch 46/50\n",
            "63/63 - 96s - loss: 0.1317 - accuracy: 0.9679 - val_loss: 1.4173 - val_accuracy: 0.7692\n",
            "Epoch 47/50\n",
            "63/63 - 95s - loss: 0.0932 - accuracy: 0.9719 - val_loss: 1.0115 - val_accuracy: 0.7500\n",
            "Epoch 48/50\n",
            "63/63 - 97s - loss: 0.0551 - accuracy: 0.9840 - val_loss: 0.9285 - val_accuracy: 0.7500\n",
            "Epoch 49/50\n",
            "63/63 - 96s - loss: 0.0544 - accuracy: 0.9780 - val_loss: 1.4127 - val_accuracy: 0.8077\n",
            "Epoch 50/50\n",
            "63/63 - 96s - loss: 0.1105 - accuracy: 0.9760 - val_loss: 1.2247 - val_accuracy: 0.8269\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2eYvRbmAWFKe"
      },
      "source": [
        ""
      ],
      "execution_count": 6,
      "outputs": []
    }
  ]
}